{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from pyquery import PyQuery\n",
    "from lxml.html import parse\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "from fpdf import FPDF\n",
    "import os\n",
    "import img2pdf\n",
    "from flask import Flask, request, jsonify, json, abort\n",
    "from flask_cors import CORS, cross_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ = \"https://www.porncomix.info/watching-my-step-jab-comix/\"\n",
    "url = ('https://www.porncomix.info/jabcomix-santo-playa-no-2/jabcomix-santo-playa-no-2-1/')\n",
    "r = get(url_)\n",
    "title = 'Step_sis_'\n",
    "\n",
    "directory = '/home/karan/Downloads/' + title + '/'\n",
    "os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step_sis_01\n",
      "Step_sis_02\n",
      "Step_sis_03\n",
      "Step_sis_04\n",
      "Step_sis_05\n",
      "Step_sis_06\n",
      "Step_sis_07\n",
      "Step_sis_08\n",
      "Step_sis_09\n",
      "Step_sis_10\n",
      "Step_sis_11\n",
      "Step_sis_12\n",
      "Step_sis_13\n",
      "Step_sis_14\n",
      "Step_sis_15\n",
      "Step_sis_16\n",
      "Step_sis_17\n",
      "Step_sis_18\n",
      "Step_sis_19\n",
      "Step_sis_20\n",
      "Step_sis_21\n",
      "Step_sis_22\n",
      "Step_sis_23\n",
      "['/home/karan/Downloads/Step_sis_/Step_sis_01.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_02.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_03.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_04.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_05.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_06.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_07.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_08.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_09.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_10.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_11.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_12.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_13.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_14.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_15.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_16.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_17.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_18.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_19.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_20.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_21.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_22.jpg', '/home/karan/Downloads/Step_sis_/Step_sis_23.jpg']\n"
     ]
    }
   ],
   "source": [
    "html = BeautifulSoup(r.content,\"html.parser\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "img_arr = []\n",
    "\n",
    "for img_page in html.find_all(\"dt\", class_=\"gallery-icon portrait\"):\n",
    "    #print(img_page)    \n",
    "    for a in img_page.find_all(\"a\", href=True):\n",
    "        count = count + 1\n",
    "        #print(a.attrs['href'])\n",
    "        b = get(a.attrs['href'])\n",
    "        \n",
    "        if count < 10:\n",
    "            count_str = \"0\" + str(count)\n",
    "        else:\n",
    "            count_str = str(count)\n",
    "        \n",
    "        page_img = BeautifulSoup(b.content,\"html.parser\").find_all(\"div\", class_=\"attachment-image\")[0].find_all(\"a\", href=True)[0].attrs['href']\n",
    "        \n",
    "        c = get(page_img)\n",
    "        \n",
    "        img_arr.append('/home/karan/Downloads/' + title + '/' + title + (count_str) + \".jpg\")\n",
    "        \n",
    "        with open('/home/karan/Downloads/' + title + '/' + title + (count_str) + \".jpg\", 'wb') as f:\n",
    "            f.write(c.content)\n",
    "            print(title + (count_str))\n",
    "            \n",
    "print(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Comix/\" + title + \".pdf\", \"wb\") as f:\n",
    "    f.write(img2pdf.convert([i for i in img_arr if i.endswith(\".jpg\")]))#os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "cors = CORS(app)\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'\n",
    "\n",
    "methods = ('GET', 'POST')\n",
    "\n",
    "metric_finders = {}\n",
    "metric_readers = {}\n",
    "annotation_readers = {}\n",
    "panel_readers = {}\n",
    "\n",
    "@app.route('/', methods=methods)\n",
    "@cross_origin()\n",
    "def hello_world():\n",
    "    print(request.headers, request.get_json())\n",
    "    return 'Jether\\'s python Grafana datasource, used for rendering HTML panels and timeseries data.'\n",
    "\n",
    "@app.route('/file')\n",
    "def root():\n",
    "    return app.send_static_file('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ = \"https://www.porncomix.info/dna-2-jabcomix/\"\n",
    "\n",
    "r = get(url_)\n",
    "title = 'DNA_'\n",
    "\n",
    "directory = '/home/karan/Downloads/' + title + '/'\n",
    "os.mkdir(directory)\n",
    "\n",
    "html = BeautifulSoup(r.content,\"html.parser\")\n",
    "\n",
    "count = 0\n",
    "\n",
    "img_arr = []\n",
    "\n",
    "for img_page in html.find_all(\"dt\", class_=\"gallery-icon portrait\"):\n",
    "    #print(img_page)    \n",
    "    for a in img_page.find_all(\"a\", href=True):\n",
    "        count = count + 1\n",
    "        #print(a.attrs['href'])\n",
    "        b = get(a.attrs['href'])\n",
    "        \n",
    "        if count < 10:\n",
    "            count_str = \"0\" + str(count)\n",
    "        else:\n",
    "            count_str = str(count)\n",
    "        \n",
    "        page_img = BeautifulSoup(b.content,\"html.parser\").find_all(\"div\", class_=\"attachment-image\")[0].find_all(\"a\", href=True)[0].attrs['href']\n",
    "        \n",
    "        c = get(page_img)\n",
    "        \n",
    "        img_arr.append('/home/karan/Downloads/' + title + '/' + title + (count_str) + \".jpg\")\n",
    "        \n",
    "        with open('/home/karan/Downloads/' + title + '/' + title + (count_str) + \".jpg\", 'wb') as f:\n",
    "            f.write(c.content)\n",
    "            print(title + (count_str))\n",
    "            \n",
    "print(img_arr)\n",
    "\n",
    "\n",
    "with open(\"Comix/\" + title + \".pdf\", \"wb\") as f:\n",
    "    f.write(img2pdf.convert([i for i in img_arr if i.endswith(\".jpg\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_page in html.find_all(\"div\", class_=\"gallery-icon\"):\n",
    "    print(img_page)\n",
    "    for a in img_page.find_all(\"a\", href=True):\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/karan/Downloads/cat3.jpg', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
